{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kerasを用いた画像分類入門\n",
    "\n",
    "Kerasを用いて、画像分類モデルを作ってみます。\n",
    "\n",
    "今回は、「ラーメン」と「うどん」の2つの画像を分類する学習モデルを作成します。\n",
    "画像分類でよく使われる、畳み込みニューラルネットワーク (CNN) は使用せず、まずは単純なニューラルネットワークのみで分類してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流れ\n",
    "\n",
    "1. データの取得\n",
    "2. データの選別\n",
    "3. モデルの構築\n",
    "4. 学習\n",
    "5. 推論\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データの取得\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はインターネットにある画像を収集して、使用します。\n",
    "インターネットから画像などの情報を収集する場合は、専用のサービス (API) を使用する方法と、\n",
    "HTMLドキュメントを解析するWebスクレイピングによる方法があります。\n",
    "今回は専用のサービスを使用する方法で、画像を収集します。\n",
    "\n",
    "今回使用するサービスは、Microsoftが提供している、「Bing Image Search API」を使用します。\n",
    "このAPIを使用して、インターネットに公開されている「ラーメン」と「うどん」の画像を収集します。\n",
    "\n",
    "取得スクリプトについては、[bing_image_search_downloder.ipynb](./bing_image_search_downloder.ipynb)のノートブックを参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データの選別"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを取得したら、データを選別する必要があります。例えば、「ラーメン」で画像検索した結果には、ラーメンそのものの画像以外にも検索結果に入ってきます。\n",
    "\n",
    "![ラーメン検索結果](./images/bing_ramen_search.png \"ラーメン検索結果\")\n",
    "\n",
    "このように、学習に必要ない画像を取り除く必要があります。\n",
    "今回はラーメンやうどんには関係なさそうな画像も一部学習データに混ざった状態になっていますが、そのまま学習のデータとして使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、取得したデータを学習するため、以下の3つのディレクトリに分けて保存します。\n",
    "\n",
    "- train\n",
    "    - モデルの学習に使用します。\n",
    "- verification\n",
    "    - モデルの学習中に、未知のデータに対してどれだけ精度が上がっているかを検証するためにしようします。\n",
    "- test\n",
    "    - モデルの学習が終わった後で、実際の推論時に使用します。\n",
    "\n",
    "ラーメン、うどん各々の画像に対して、trainデータ300件、verificationデータ100件、testデータ100件ずつ格納していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の保存フォルダには、以下のようになっています。\n",
    "\n",
    "```\n",
    "noodles\n",
    "├── test\n",
    "│   ├── ramen\n",
    "│   │   ├── 007a9f3ee253e4e00e91a86f79d96251.jpg\n",
    "│   │   ├── 01b2931a076face741042e491d03d03c.jpg\n",
    "│   │   ├── 047a34512b2f554df476f924956d9324.jpg\n",
    "│   │   ├── 11cb359269c9b59de1c150e4a21b6266.jpg\n",
    "│   │   ├── 12521618a6169010cfdfa319b2cd66a6.jpg\n",
    "│   │\n",
    "│   │\n",
    "│   └── udon\n",
    "│       ├── 018e203f3bb9cfd9b407e90a2f975d30.jpg\n",
    "│       ├── 0543055a3987c79c07b6abdbcd608cd6.jpg\n",
    "│       ├── 094c1922e08cbd1fc5c890309a73c91a.jpg\n",
    "│       ├── 111d37eb4ac7cfa268001133857db4ec.jpg\n",
    "│       ├── 111ec27a535af2c06a32726a63c0629e.jpg\n",
    "│\n",
    "│   \n",
    "├── train\n",
    "│   ├── ramen\n",
    "│   │   ├── 01375acfef42ca0296d994319ab370d5.jpg\n",
    "│   │   ├── 02f5f33eaa99f544d1b56dd43acc12e7.jpg\n",
    "│   │   ├── 03477d329e51964eca3d5350513bdc5b.jpg\n",
    "│   │   ├── 03da108a718435ed77080f050bac7733.jpg\n",
    "│   │   ├── 061bf905ebbba6fd7719ac3322b34f9b.jpg\n",
    "│   │\n",
    "│   │\n",
    "│   └── udon\n",
    "│       ├── 0008ccb95ea65115c9c91b973fa3d13a.jpg\n",
    "│       ├── 025e6f3e0c0426c4b88737621854453f.jpg\n",
    "│       ├── 02608a29fe16132807e9cbfc15a40703.jpg\n",
    "│       ├── 038d39af3f843334906a0c559c2eeb64.jpg\n",
    "│       ├── 047262dd8a3f5e1822aa10a828fd6433.jpg\n",
    "│\n",
    "│\n",
    "└── validaiton\n",
    "    ├── ramen\n",
    "    │   ├── 0220d9d1e8bf2906553a81e29e08e24b.png\n",
    "    │   ├── 03f8f134736f585014a340f5e9e147d1.jpg\n",
    "    │   ├── 04d9bfe2d8437ed5072f2f183ad41511.jpg\n",
    "    │   ├── 086cde8b41aef5076d51d73dc8d601e1.jpg\n",
    "    │   ├── 08f78c8e2e53989a68d7e3b864bd579f.jpg\n",
    "    │\n",
    "    │\n",
    "    └── udon\n",
    "        ├── 0035a169051a0afbd792f30a82934a3e.jpg\n",
    "        ├── 005b96c51ae7adbc7acc5c4e4a790fbb.jpg\n",
    "        ├── 06078751ab342a44bedc08e235d5ef5c.jpg\n",
    "        ├── 0ba18a8a8b878dd11c7076f0f71cda63.jpg\n",
    "        ├── 0d3486e1682132d6bdd36a623dde48a4.jpg\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "APIで取得した画像を上記のディレクトリに格納するスクリプトは、[copy_to_train_validation_test.ipynb](./copy_to_train_validation_test.ipynb)を参照ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colaboratoryでの設定 (学習データのコピー)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabを利用されている方は、以下のコマンドを利用してGoogle Driveをマウントし、\n",
    "# noodles.zipファイルをColabコンテナにコピーしておきましょう。\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/gdrive/My\\ Drive/GD_share01/noodles.zip -d /content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さてここで、実際にKerasを使ってディープラーニングの学習モデルを構築していきます。\n",
    "まずは、単純な全結合層を3つほど使った多層ニューラルネットワークモデルを作っていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力データの生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像ファイルが格納されたディレクトリからデータを読み込んで、学習モデルに入力するための準備を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = './noodles/train/'\n",
    "validation_dir = './noodles/validaiton/'\n",
    "test_dir = './noodles/test/'\n",
    "\n",
    "image_size = (128, 128)  # 入力データの縦横のサイズ。画像ファイルはこのサイズに自動的にリサイズされる。\n",
    "batch_size = 32  # バッチサイズ。1度に取り込む入力データの数。\n",
    "\n",
    "image_data_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "# 画像データはRGBの値が0から255までの値になっているので、\n",
    "# rescaleして値を0から1までの範囲にすることで、学習の収束を早くする。\n",
    "\n",
    "train_generator = image_data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "validation_generator = image_data_generator.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_generator = image_data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(128,128,3)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのコンパイル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習モデルに対して、損失関数、オプティマイザ、評価方法を設定し、コンパイルします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',   # 今回は「多クラス分類」を扱うため、損失関数を「categorical_crossentropy」に設定する\n",
    "    optimizer='adam',  # オプティマイザに「Adam」を使用\n",
    "    metrics=['acc']  # 評価方法は「正答率」 (accuracy)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "構築したモデルを実際に学習していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # エポック数。全ての入力データを何回繰り返して学習するかを指定する。\n",
    "train_steps = 300 // batch_size    # エポックあたりのステップ数。\n",
    "validation_steps = 100 // batch_size\n",
    "test_steps = 100 // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "# 学習の推移を、historyに格納しておく\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の推移をグラフ化してみてみよう。\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']  # 学習データの正答率\n",
    "val_acc = history.history['val_acc']  # 検証データの正答率\n",
    "loss = history.history['loss']  # 学習データの損失\n",
    "val_loss = history.history['val_loss']  # 検証データの損失\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, label='Train Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデルを保存\n",
    "model.save('noodle_model1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済モデルを使って、テストデータを推論してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "code_to_class = {0: 'ラーメン', 1: 'うどん'}\n",
    "\n",
    "x, y = next(test_generator)\n",
    "y_true = np.argmax(y, axis=1)\n",
    "y_prob = model.predict_on_batch(x)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    plt.imshow(x[i])\n",
    "    plt.show()\n",
    "    print('推定：', code_to_class[y_pred[i]])\n",
    "    print('正解：', code_to_class[y_true[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列で見てみる\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混同行列は、以下のような内容になっています。\n",
    "\n",
    "|↓教師データ ／ 出力結果→| 0: ラーメン | 1: うどん |\n",
    "|:---|:---|:---|\n",
    "|0: ラーメン|正しくラーメンと判定した|ラーメンなのに、うどんと判定した|\n",
    "|1: うどん|うどんなのに、ラーメンと判定した|正しくうどんと判定した|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳込みニューラルネットワークを構築する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層のみのネットワークは精度がいいとは言えませんね。\n",
    "そこで、先ほどのモデルを改良して、今度は畳込みニューラルネットワークを構築します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力データの生成\n",
    "\n",
    "先ほどと同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = './noodles/train/'\n",
    "validation_dir = './noodles/validaiton/'\n",
    "test_dir = './noodles/test/'\n",
    "\n",
    "image_size = (128, 128)  # 入力データの縦横のサイズ。画像ファイルはこのサイズに自動的にリサイズされる。\n",
    "batch_size = 32  # バッチサイズ。1度に取り込む入力データの数。\n",
    "\n",
    "image_data_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "# 画像データはRGBの値が0から255までの値になっているので、\n",
    "# rescaleして値を0から1までの範囲にすることで、学習の収束を早くする。\n",
    "\n",
    "train_generator = image_data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "validation_generator = image_data_generator.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_generator = image_data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構築\n",
    "\n",
    "畳込み層である「Conv2D」とプーリング層である「MaxPool2D」を追加しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), strides=(1,1), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPool2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルのコンパイル以降の処理は同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',   # 今回は「多クラス分類」を扱うため、損失関数を「categorical_crossentropy」に設定する\n",
    "    optimizer='adam',  # オプティマイザに「Adam」を使用\n",
    "    metrics=['acc']  # 評価方法は「正答率」 (accuracy)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # エポック数。全ての入力データを何回繰り返して学習するかを指定する。\n",
    "train_steps = 300 // batch_size    # エポックあたりのステップ数。\n",
    "validation_steps = 100 // batch_size\n",
    "test_steps = 100 // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "# 学習の推移を、historyに格納しておく\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の推移をグラフ化してみてみよう。\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']  # 学習データの正答率\n",
    "val_acc = history.history['val_acc']  # 検証データの正答率\n",
    "loss = history.history['loss']  # 学習データの損失\n",
    "val_loss = history.history['val_loss']  # 検証データの損失\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, label='Train Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデルを保存\n",
    "model.save('noodle_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "code_to_class = {0: 'ラーメン', 1: 'うどん'}\n",
    "\n",
    "x, y = next(test_generator)\n",
    "y_true = np.argmax(y, axis=1)\n",
    "y_prob = model.predict_on_batch(x)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    plt.imshow(x[i])\n",
    "    plt.show()\n",
    "    print('推定：', code_to_class[y_pred[i]])\n",
    "    print('正解：', code_to_class[y_true[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列で見てみる\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## もっと精度を上げるには？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もっと精度を上げるには、以下の方法が考えられます。\n",
    "\n",
    "- データの数を増やす\n",
    "    - 学習データの数を300→1,000に増やしてみる\n",
    "- エポック数を増やす\n",
    "    - エポック数を10→50に増やしてみる\n",
    "- 層を増やしてみる\n",
    "    - 全結合層などの層の数を増やしてみる\n",
    "- カーネル(フィルタ)の数を増やしてみる\n",
    "    - 畳み込み層のカーネルの数を増やしてみる\n",
    "- データ拡張(data augmentation)を行い、データを水増しする\n",
    "    - KerasのImageDataGeneratorのオプションを使って、画像をランダムに変形させて水増ししてみる\n",
    "- Dropoutなどを用いて過学習を抑制してみる\n",
    "    - Dropoutや正則化などの手法を用いて、過学習を防ぐ\n",
    "- 著名なモデルを使用する\n",
    "    - Kerasでは、よく使うモデルを簡単に利用できる\n",
    "    - 代表的なモデル:\n",
    "        - VGG16 / VGG19\n",
    "        - ResNet\n",
    "    - 詳細はKerasのサイトをご確認ください。 [https://keras.io/ja/applications/](https://keras.io/ja/applications/)\n",
    "- すでに学習済みの著名なモデルを使用し、転移学習／ファインチューニングをする\n",
    "    - 学習済みモデルを使用し、こちらでカスタマイズして利用すると、少ないデータ数でも精度の良いモデルが出来上がることが多い。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "昨年開催された「第57回 長岡IT開発者勉強会」(NDS)にて、Kerasを使った画像分類を紹介しています。新潟の名産品4種の画像を分類するために、VGG16をファインチューニングして学習しています。\n",
    "\n",
    "- スライド資料: [https://speakerdeck.com/kasacchiful/nds57](https://speakerdeck.com/kasacchiful/nds57)\n",
    "- ノートブック: [https://github.com/kasacchiful/nds57-sample/blob/master/nds57_vgg16_sample.ipynb](https://github.com/kasacchiful/nds57-sample/blob/master/nds57_vgg16_sample.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
